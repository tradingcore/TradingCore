"""
Script principal do TradingCore.
Processa todos os usu√°rios e envia an√°lises di√°rias.

OTIMIZADO: Processa cada ticker apenas uma vez, reutilizando
an√°lises para m√∫ltiplos usu√°rios que compartilham os mesmos tickers.
"""
from src.config import validar_configuracoes
from src.utils import calcular_periodo_24h, parsear_tickers, extrair_tickers_unicos
from src.sheets_client import carregar_usuarios_sheets
from src.news_fetcher import buscar_noticias
from src.ai_analyzer import (
    analisar_com_gpt,
    filtrar_top_relevantes,
    gerar_resumo_executivo
)
from src.email_sender import gerar_email_html, enviar_email


def processar_todos_tickers(tickers_unicos, data_inicio, data_fim):
    """
    Processa todos os tickers √∫nicos uma √∫nica vez.
    
    Args:
        tickers_unicos: Set de tickers √∫nicos
        data_inicio: Data in√≠cio da busca
        data_fim: Data fim da busca
        
    Returns:
        Tupla (cache_analises, cache_resumos):
            - cache_analises: {ticker: lista_de_analises}
            - cache_resumos: {ticker: resumo_executivo_texto}
    """
    cache_analises = {}
    cache_resumos = {}
    total_tickers = len(tickers_unicos)
    
    print(f"\n{'='*60}")
    print(f"üìä FASE 1: PROCESSANDO {total_tickers} TICKERS √öNICOS")
    print(f"{'='*60}")
    
    for idx, ticker in enumerate(sorted(tickers_unicos), 1):
        try:
            print(f"\n[{idx}/{total_tickers}] Processando {ticker}...")
            
            # Buscar not√≠cias (1x por ticker)
            artigos = buscar_noticias(ticker, data_inicio, data_fim)
            
            if not artigos:
                print(f"  ‚ö† {ticker}: Nenhuma not√≠cia encontrada")
                cache_analises[ticker] = []
                continue
            
            # Analisar com GPT (1x por ticker)
            analises = analisar_com_gpt(artigos, ticker)
            
            if not analises:
                print(f"  ‚ö† {ticker}: Nenhuma an√°lise gerada")
                cache_analises[ticker] = []
                continue
            
            # Filtrar top relevantes
            top_analises = filtrar_top_relevantes(analises)
            
            print(f"  ‚úì {ticker}: {len(top_analises)} not√≠cias relevantes selecionadas")
            
            # Armazenar no cache
            cache_analises[ticker] = top_analises
            
        except Exception as e:
            print(f"  ‚úó Erro ao processar {ticker}: {e}")
            cache_analises[ticker] = []
            continue
    
    # =========================================================
    # Gerar resumos executivos (1x por ticker com not√≠cias)
    # =========================================================
    print(f"\n{'='*60}")
    print(f"üìù GERANDO RESUMOS EXECUTIVOS")
    print(f"{'='*60}")
    
    for ticker, analises in cache_analises.items():
        if analises:
            # Gera resumo executivo para este ticker (1x)
            resumo = gerar_resumo_executivo(analises)
            cache_resumos[ticker] = resumo.get(ticker, "")
    
    # Resumo da fase 1
    tickers_com_noticias = sum(1 for t, a in cache_analises.items() if a)
    total_noticias_cache = sum(len(a) for a in cache_analises.values())
    
    print(f"\n{'='*60}")
    print(f"‚úì FASE 1 CONCLU√çDA")
    print(f"  Tickers processados: {total_tickers}")
    print(f"  Tickers com not√≠cias: {tickers_com_noticias}")
    print(f"  Resumos executivos gerados: {len(cache_resumos)}")
    print(f"  Total de an√°lises em cache: {total_noticias_cache}")
    print(f"{'='*60}")
    
    return cache_analises, cache_resumos


def processar_usuario(usuario_dict, cache_analises, cache_resumos):
    """
    Processa um √∫nico usu√°rio usando os caches de an√°lises e resumos.
    
    Args:
        usuario_dict: Dicion√°rio com dados do usu√°rio
        cache_analises: Dicion√°rio {ticker: lista_de_analises}
        cache_resumos: Dicion√°rio {ticker: resumo_executivo_texto}
        
    Returns:
        Tupla (sucesso: bool, num_noticias: int)
    """
    nome = usuario_dict.get('Qual seu nome completo?', 'N/A')
    email = usuario_dict.get('Qual seu e-mail?', '')
    ticker_str = usuario_dict.get('Ticker 1', '')

    print(f"\n  Processando: {nome} ({email})")

    # Validar email
    if not email or '@' not in email:
        print(f"    ‚úó Email inv√°lido: {email}")
        return False, 0

    # Parsear tickers do usu√°rio
    tickers = parsear_tickers(ticker_str)
    if not tickers:
        print(f"    ‚ö† Nenhum ticker encontrado")
        html = gerar_email_html(usuario_dict, [], {})
        enviar_email(email, "TradingCore - An√°lise Di√°ria", html)
        return True, 0

    print(f"    Tickers: {', '.join(tickers)}")
    
    # Coletar an√°lises do cache para os tickers do usu√°rio
    todas_analises = []
    for ticker in tickers:
        analises_ticker = cache_analises.get(ticker, [])
        todas_analises.extend(analises_ticker)

    # Coletar resumos executivos do cache (sem nova chamada API!)
    resumo_executivo = {}
    for ticker in tickers:
        if ticker in cache_resumos and cache_resumos[ticker]:
            resumo_executivo[ticker] = cache_resumos[ticker]

    # Gerar e enviar email
    try:
        html = gerar_email_html(usuario_dict, todas_analises, resumo_executivo)

        sucesso = enviar_email(
            email,
            f"TradingCore - An√°lise Di√°ria ({len(todas_analises)} not√≠cias)",
            html
        )

        if sucesso:
            print(f"    ‚úì Email enviado! {len(todas_analises)} not√≠cias")

        return sucesso, len(todas_analises)

    except Exception as e:
        print(f"    ‚úó Erro ao enviar email: {e}")
        return False, len(todas_analises)


def main():
    """Fun√ß√£o principal que executa o processamento completo."""
    print("\n" + "="*60)
    print("üöÄ TRADINGCORE - INICIANDO PROCESSAMENTO")
    print("="*60)

    # Validar configura√ß√µes
    try:
        validar_configuracoes()
    except ValueError as e:
        print(f"\n‚úó {e}")
        return

    # Calcular per√≠odo
    data_inicio, data_fim = calcular_periodo_24h()
    print(f"\nüìÖ Per√≠odo: {data_inicio} a {data_fim}")

    # Carregar usu√°rios
    print(f"\nüìä Carregando usu√°rios...")
    df_usuarios = carregar_usuarios_sheets()

    if df_usuarios.empty:
        print("‚úó Nenhum usu√°rio encontrado!")
        return

    print(f"‚úì {len(df_usuarios)} usu√°rios carregados")

    # =========================================================
    # FASE 1: Extrair e processar tickers √∫nicos
    # =========================================================
    tickers_unicos = extrair_tickers_unicos(df_usuarios)
    
    if not tickers_unicos:
        print("‚úó Nenhum ticker encontrado em nenhum usu√°rio!")
        return
    
    print(f"‚úì {len(tickers_unicos)} tickers √∫nicos identificados: {', '.join(sorted(tickers_unicos))}")
    
    # Processar todos os tickers uma √∫nica vez
    cache_analises, cache_resumos = processar_todos_tickers(tickers_unicos, data_inicio, data_fim)

    # =========================================================
    # FASE 2: Distribuir an√°lises para cada usu√°rio
    # =========================================================
    print(f"\n{'='*60}")
    print(f"üìß FASE 2: ENVIANDO EMAILS PARA {len(df_usuarios)} USU√ÅRIOS")
    print(f"{'='*60}")

    # Estat√≠sticas
    total_usuarios = len(df_usuarios)
    usuarios_sucesso = 0
    usuarios_erro = 0
    total_noticias = 0

    # Processar cada usu√°rio usando os caches (sem novas chamadas API!)
    for idx, row in df_usuarios.iterrows():
        try:
            usuario_dict = row.to_dict()
            sucesso, num_noticias = processar_usuario(usuario_dict, cache_analises, cache_resumos)

            if sucesso:
                usuarios_sucesso += 1
                total_noticias += num_noticias
            else:
                usuarios_erro += 1

        except Exception as e:
            print(f"\n‚úó Erro cr√≠tico ao processar usu√°rio {idx}: {e}")
            usuarios_erro += 1
            continue

    # Resumo final
    print("\n" + "="*60)
    print("üìä RESUMO DO PROCESSAMENTO")
    print("="*60)
    print(f"Tickers √∫nicos processados: {len(tickers_unicos)}")
    print(f"Total de usu√°rios: {total_usuarios}")
    print(f"‚úì Sucesso: {usuarios_sucesso}")
    print(f"‚úó Erro: {usuarios_erro}")
    print(f"üì∞ Total de not√≠cias enviadas: {total_noticias}")
    print(f"üìà M√©dia de not√≠cias por usu√°rio: {total_noticias/max(usuarios_sucesso,1):.1f}")
    print("="*60)
    print("‚úÖ PROCESSAMENTO CONCLU√çDO!")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
