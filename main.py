"""
Script principal do TradingCore.
Processa todos os usu√°rios e envia an√°lises di√°rias.

OTIMIZADO: Processa cada ticker apenas uma vez, reutilizando
an√°lises para m√∫ltiplos usu√°rios que compartilham os mesmos tickers.
CONTEXTUAL: Usa tese estrat√©gica de cada empresa para qualificar as not√≠cias.
"""
from src.config import validar_configuracoes
from src.utils import calcular_periodo_24h, parsear_tickers, extrair_tickers_unicos
from src.sheets_client import carregar_usuarios_sheets
from src.news_fetcher import buscar_noticias
from src.context_manager import garantir_contexto
from src.ai_analyzer import (
    analisar_com_gpt,
    filtrar_top_relevantes,
    gerar_resumo_executivo
)
from src.email_sender import gerar_email_html, enviar_email
from src.price_fetcher import buscar_precos_multiplos


def processar_todos_tickers(tickers_unicos, data_inicio, data_fim):
    """
    Processa todos os tickers √∫nicos uma √∫nica vez.
    
    Args:
        tickers_unicos: Set de tickers √∫nicos
        data_inicio: Data in√≠cio da busca
        data_fim: Data fim da busca
        
    Returns:
        Tupla (cache_analises, cache_resumos, cache_contextos, analises_consolidadas):
            - cache_analises: {ticker: lista_de_analises}
            - cache_resumos: {ticker: resumo_executivo_texto}
            - cache_contextos: {ticker: contexto_texto}
            - analises_consolidadas: {ticker: {'positivo': str, 'negativo': str}}
    """
    cache_analises = {}
    cache_resumos = {}
    cache_contextos = {}
    total_tickers = len(tickers_unicos)
    
    print(f"\n{'='*60}")
    print(f"üìä FASE 1: PROCESSANDO {total_tickers} TICKERS √öNICOS")
    print(f"{'='*60}")
    
    for idx, ticker in enumerate(sorted(tickers_unicos), 1):
        try:
            print(f"\n[{idx}/{total_tickers}] Processando {ticker}...")
            
            # 1. Garantir contexto estrat√©gico (Carrega ou gera via GPT-4o)
            contexto = garantir_contexto(ticker)
            cache_contextos[ticker] = contexto
            
            # 2. Buscar not√≠cias (1x por ticker)
            artigos = buscar_noticias(ticker, data_inicio, data_fim)
            
            if not artigos:
                print(f"  ‚ö† {ticker}: Nenhuma not√≠cia encontrada")
                cache_analises[ticker] = []
                continue
            
            # 3. Analisar com GPT (1x por ticker, usando o contexto)
            analises = analisar_com_gpt(artigos, ticker, contexto)
            
            if not analises:
                print(f"  ‚ö† {ticker}: Nenhuma an√°lise gerada")
                cache_analises[ticker] = []
                continue
            
            # 4. Filtrar top relevantes (baseado no relevancia_score)
            top_analises = filtrar_top_relevantes(analises)
            
            print(f"  ‚úì {ticker}: {len(top_analises)} not√≠cias relevantes selecionadas")
            
            # Armazenar no cache
            cache_analises[ticker] = top_analises
            
        except Exception as e:
            print(f"  ‚úó Erro ao processar {ticker}: {e}")
            cache_analises[ticker] = []
            continue
    
    # =========================================================
    # Gerar resumos executivos (1x por ticker com not√≠cias)
    # =========================================================
    print(f"\n{'='*60}")
    print(f"üìù GERANDO RESUMOS EXECUTIVOS")
    print(f"{'='*60}")
    
    for ticker, analises in cache_analises.items():
        if analises:
            # Gera resumo executivo para este ticker (1x, usando contexto)
            resumo = gerar_resumo_executivo(analises, cache_contextos)
            cache_resumos[ticker] = resumo.get(ticker, "")
    
    # Resumo da fase 1
    tickers_com_noticias = sum(1 for t, a in cache_analises.items() if a)
    total_noticias_cache = sum(len(a) for a in cache_analises.values())
    
    # Gerar an√°lises consolidadas
    print(f"\n{'='*60}")
    print(f"üìä GERANDO AN√ÅLISES CONSOLIDADAS")
    print(f"{'='*60}")
    
    from src.ai_analyzer import gerar_analise_consolidada
    analises_consolidadas = gerar_analise_consolidada(cache_analises, cache_contextos)
    
    print(f"\n{'='*60}")
    print(f"‚úì FASE 1 CONCLU√çDA")
    print(f"  Tickers processados: {total_tickers}")
    print(f"  Tickers com not√≠cias: {tickers_com_noticias}")
    print(f"  Resumos executivos gerados: {len(cache_resumos)}")
    print(f"  An√°lises consolidadas geradas: {len(analises_consolidadas)}")
    print(f"  Total de an√°lises em cache: {total_noticias_cache}")
    print(f"{'='*60}")
    
    return cache_analises, cache_resumos, cache_contextos, analises_consolidadas


def processar_usuario(usuario_dict, cache_analises, cache_resumos, precos_dados, analises_consolidadas):
    """
    Processa um √∫nico usu√°rio usando os caches de an√°lises, resumos, pre√ßos e an√°lises consolidadas.
    
    Args:
        usuario_dict: Dicion√°rio com dados do usu√°rio
        cache_analises: Dicion√°rio {ticker: lista_de_analises}
        cache_resumos: Dicion√°rio {ticker: resumo_executivo_texto}
        precos_dados: Dicion√°rio {ticker: {preco_fechamento, variacao_percentual, sucesso}}
        analises_consolidadas: Dicion√°rio {ticker: {'positivo': str, 'negativo': str}}
        
    Returns:
        Tupla (sucesso: bool, num_noticias: int)
    """
    nome = usuario_dict.get('Qual seu nome completo?', 'N/A')
    email = usuario_dict.get('Qual seu e-mail?', '')
    ticker_str = usuario_dict.get('Ticker 1', '')

    print(f"\n  Processando: {nome} ({email})")

    # Validar email
    if not email or '@' not in email:
        print(f"    ‚úó Email inv√°lido: {email}")
        return False, 0

    # Parsear tickers do usu√°rio
    tickers = parsear_tickers(ticker_str)
    if not tickers:
        print(f"    ‚ö† Nenhum ticker encontrado")
        html = gerar_email_html(usuario_dict, [], {}, {}, {})
        enviar_email(email, "TradingCore - An√°lise Di√°ria", html)
        return True, 0

    print(f"    Tickers: {', '.join(tickers)}")
    
    # Coletar an√°lises do cache para os tickers do usu√°rio
    todas_analises = []
    for ticker in tickers:
        analises_ticker = cache_analises.get(ticker, [])
        todas_analises.extend(analises_ticker)

    # Coletar resumos executivos do cache
    resumo_executivo = {}
    for ticker in tickers:
        if ticker in cache_resumos and cache_resumos[ticker]:
            resumo_executivo[ticker] = cache_resumos[ticker]

    # Filtrar apenas os pre√ßos dos tickers do usu√°rio
    precos_usuario = {t: precos_dados.get(t, {'sucesso': False}) for t in tickers}
    
    # Filtrar apenas as an√°lises consolidadas dos tickers do usu√°rio
    consolidadas_usuario = {t: analises_consolidadas.get(t, {}) for t in tickers if t in analises_consolidadas}

    # Gerar e enviar email
    try:
        html = gerar_email_html(usuario_dict, todas_analises, resumo_executivo, precos_usuario, consolidadas_usuario)

        sucesso = enviar_email(
            email,
            f"TradingCore - An√°lise Di√°ria ({len(todas_analises)} not√≠cias)",
            html
        )

        if sucesso:
            print(f"    ‚úì Email enviado! {len(todas_analises)} not√≠cias")

        return sucesso, len(todas_analises)

    except Exception as e:
        print(f"    ‚úó Erro ao enviar email: {e}")
        return False, len(todas_analises)


def main():
    """Fun√ß√£o principal que executa o processamento completo."""
    print("\n" + "="*60)
    print("üöÄ TRADINGCORE - INICIANDO PROCESSAMENTO")
    print("="*60)

    # Validar configura√ß√µes
    try:
        validar_configuracoes()
    except ValueError as e:
        print(f"\n‚úó {e}")
        return

    # Calcular per√≠odo
    data_inicio, data_fim = calcular_periodo_24h()
    print(f"\nüìÖ Per√≠odo: {data_inicio} a {data_fim}")

    # Carregar usu√°rios
    print(f"\nüìä Carregando usu√°rios...")
    df_usuarios = carregar_usuarios_sheets()

    if df_usuarios.empty:
        print("‚úó Nenhum usu√°rio encontrado!")
        return

    print(f"‚úì {len(df_usuarios)} usu√°rios carregados")

    # =========================================================
    # FASE 1: Extrair e processar tickers √∫nicos
    # =========================================================
    tickers_unicos = extrair_tickers_unicos(df_usuarios)
    
    if not tickers_unicos:
        print("‚úó Nenhum ticker encontrado em nenhum usu√°rio!")
        return
    
    print(f"‚úì {len(tickers_unicos)} tickers √∫nicos identificados: {', '.join(sorted(tickers_unicos))}")
    
    # Processar todos os tickers uma √∫nica vez
    cache_analises, cache_resumos, _, analises_consolidadas = processar_todos_tickers(tickers_unicos, data_inicio, data_fim)

    # =========================================================
    # FASE 1.5: Buscar pre√ßos do Yahoo Finance
    # =========================================================
    precos_dados = buscar_precos_multiplos(tickers_unicos)

    # =========================================================
    # FASE 2: Distribuir an√°lises para cada usu√°rio
    # =========================================================
    print(f"\n{'='*60}")
    print(f"üìß FASE 2: ENVIANDO EMAILS PARA {len(df_usuarios)} USU√ÅRIOS")
    print(f"{'='*60}")

    # Estat√≠sticas
    total_usuarios = len(df_usuarios)
    usuarios_sucesso = 0
    usuarios_erro = 0
    total_noticias = 0

    # Processar cada usu√°rio usando os caches
    for idx, row in df_usuarios.iterrows():
        try:
            usuario_dict = row.to_dict()
            sucesso, num_noticias = processar_usuario(usuario_dict, cache_analises, cache_resumos, precos_dados, analises_consolidadas)

            if sucesso:
                usuarios_sucesso += 1
                total_noticias += num_noticias
            else:
                usuarios_erro += 1

        except Exception as e:
            print(f"\n‚úó Erro cr√≠tico ao processar usu√°rio {idx}: {e}")
            usuarios_erro += 1
            continue

    # Resumo final
    print("\n" + "="*60)
    print("üìä RESUMO DO PROCESSAMENTO")
    print("="*60)
    print(f"Tickers √∫nicos processados: {len(tickers_unicos)}")
    print(f"Total de usu√°rios: {total_usuarios}")
    print(f"‚úì Sucesso: {usuarios_sucesso}")
    print(f"‚úó Erro: {usuarios_erro}")
    print(f"üì∞ Total de not√≠cias enviadas: {total_noticias}")
    print(f"üìà M√©dia de not√≠cias por usu√°rio: {total_noticias/max(usuarios_sucesso,1):.1f}")
    print("="*60)
    print("‚úÖ PROCESSAMENTO CONCLU√çDO!")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
